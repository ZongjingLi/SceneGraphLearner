{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "B = 2\n",
    "shuffle = 1\n",
    "#dataset = ToyDataWithQuestions(split = \"train\", resolution = (128,128))\n",
    "dataset = SpriteWithQuestions(resolution = (128,128))\n",
    "dataloader = DataLoader(dataset, batch_size = B, shuffle = shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28da186a0>"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [Get A Sample Data]\n",
    "for sample in dataloader:\n",
    "    sample = sample\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(sample[\"image\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': ['not generated yet.',\n",
       "   'not generated yet.',\n",
       "   'not generated yet.',\n",
       "   'not generated yet.'],\n",
       "  'program': ['exist(filter(scene(),Circle))',\n",
       "   'exist(filter(scene(),Cube))',\n",
       "   'exist(filter(scene(),Diamond))',\n",
       "   'count(scene())'],\n",
       "  'answer': ['False', 'True', 'True', '2']},\n",
       " {'question': ['not generated yet.',\n",
       "   'not generated yet.',\n",
       "   'not generated yet.',\n",
       "   'not generated yet.'],\n",
       "  'program': ['exist(filter(scene(),Circle))',\n",
       "   'exist(filter(scene(),Cube))',\n",
       "   'exist(filter(scene(),Diamond))',\n",
       "   'count(scene())'],\n",
       "  'answer': ['True', 'True', 'True', '3']}]"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collect_qa_batch(batch_qa):\n",
    "    batch_wise_qa = []\n",
    "    \n",
    "    for b in range(len(batch_qa[0][\"program\"])):\n",
    "        questions_in_batch = {\"question\":[],\"program\":[],\"answer\":[]}\n",
    "        for qpair in batch_qa:\n",
    "\n",
    "            try:questions_in_batch[\"question\"].append(qpair[\"question\"][b])\n",
    "            except: questions_in_batch[\"question\"].append(\"not generated yet.\")\n",
    "            questions_in_batch[\"program\"].append(qpair[\"program\"][b])\n",
    "            questions_in_batch[\"answer\"].append(qpair[\"answer\"][b])\n",
    "        batch_wise_qa.append(questions_in_batch)\n",
    "    return batch_wise_qa\n",
    "\n",
    "collect_qa_batch(sample[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tree(scores, connections, scale = 1.2):\n",
    "    fig = plt.figure(\"tree-visualize\",frameon = False)\n",
    "    plt.tick_params(left = False, right = False , labelleft = False ,\n",
    "                labelbottom = False, bottom = False)\n",
    "    plt.axis(\"off\")\n",
    "    x_locs = []; y_locs = []\n",
    "    for i,score in enumerate(reversed(scores)):\n",
    "        num_nodes = len(score)\n",
    "        # calculate scores each node\n",
    "        #print(score.sigmoid())\n",
    "        #score = (score.sigmoid() + 0.5).int()\n",
    "        #scores = score.sigmoid()\n",
    "        score = torch.clamp(score,0.05,1)\n",
    "\n",
    "        y_positions = [-scale*(i+1) / 2.0] * num_nodes\n",
    "        x_positions = np.linspace(-scale**(i+1), scale**(i+1), num_nodes)\n",
    "        if num_nodes == 1: x_positions = [0.0]\n",
    "        x_locs.append(x_positions); y_locs.append(y_positions)\n",
    "        \n",
    "        plt.scatter(x_positions, y_positions, alpha = score, color = 'white', linewidths=2.0)\n",
    "    for k,connection in enumerate(reversed(connections)):\n",
    "        connection = connection\n",
    "        \n",
    "        lower_node_num = len(x_locs[k])\n",
    "        upper_node_num = len(x_locs[k+1])\n",
    "        for i in range(lower_node_num):\n",
    "            for j in range(upper_node_num):\n",
    "                plt.plot( [x_locs[k][i],x_locs[k+1][j]], [y_locs[k][i], y_locs[k+1][j]], color = \"white\" ,alpha = float(connection[j][i]))\n",
    "    plt.tick_params(left = False, right = False , labelleft = False ,\n",
    "                labelbottom = False, bottom = False)\n",
    "\n",
    "def answer_distribution_binary(score, name = \"answer_distribution\"):\n",
    "    batch_size = 1\n",
    "    score_size = 4\n",
    "\n",
    "    row = batch_size * score_size \n",
    "    col = row / 2\n",
    "\n",
    "    scores = [score, 1 - score]\n",
    "\n",
    "    plt.figure(\"dists\", frameon = False, figsize = (row,col))\n",
    "    plt.tick_params(left = True, right = False , labelleft = True ,\n",
    "                labelbottom = True, bottom = True)\n",
    "    plt.cla()\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        plt.subplot(1,batch_size,i + 1,frameon=False)\n",
    "        plt.cla()\n",
    "\n",
    "        \n",
    "        keys = [\"yes\",\"no\"]\n",
    "        plt.bar(keys,scores)\n",
    "        plt.tick_params(left = True, right = False , labelleft = True ,\n",
    "                labelbottom = True, bottom = True)\n",
    "\n",
    "    plt.savefig(\"outputs/{}.png\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.perception = \"valkyr\"\n",
    "model = SceneLearner(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pose(x, att):\n",
    "    x = x.permute(0,2,1)\n",
    "    # x: B3N, att: B1KN1\n",
    "    # ts: B3k1\n",
    "    pai = att.sum(dim=3, keepdim=True) # B1K11\n",
    "    att = att / torch.clamp(pai, min=1e-3)\n",
    "    ts = torch.sum(\n",
    "        att * x[:, :, None, :, None], dim=3) # B3K1\n",
    "    return ts\n",
    "\n",
    "def equillibrium_loss(att):\n",
    "    pai = att.sum(dim=3, keepdim=True) # B1K11\n",
    "    loss_att_amount = torch.var(pai.reshape(pai.shape[0], -1), dim=1).mean()\n",
    "    return loss_att_amount\n",
    "\n",
    "\n",
    "def spatial_variance(x, att, norm_type=\"l2\"):\n",
    "    \n",
    "    pai = att.sum(dim=3, keepdim=True) # B1K11\n",
    "    att = att / torch.clamp(pai, min=1e-3)\n",
    "    ts = torch.sum(\n",
    "        att * x[:, :, None, :, None], dim=3) # B3K1\n",
    "\n",
    "    x_centered = x[:, :, None] - ts # B3KN\n",
    "    x_centered = x_centered.permute(0, 2, 3, 1) # BKN3\n",
    "    att = att.squeeze(1) # BKN1\n",
    "    cov = torch.matmul(\n",
    "        x_centered.transpose(3, 2), att * x_centered) # BK33\n",
    "    \n",
    "    # l2 norm\n",
    "    vol = torch.diagonal(cov, dim1=-2, dim2=-1).sum(2) # BK\n",
    "    if norm_type == \"l2\":\n",
    "        vol = vol.norm(dim=1).mean()\n",
    "    elif norm_type == \"l1\":\n",
    "        vol = vol.sum(dim=1).mean()\n",
    "    else:\n",
    "        # vol, _ = torch.diagonal(cov, dim1=-2, dim2=-1).sum(2).max(dim=1)\n",
    "        raise NotImplementedError\n",
    "    return vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from types import SimpleNamespace\n",
    "\n",
    "def evaluate_pose(x, att):\n",
    "    # x: B3N, att: B1KN1\n",
    "    # ts: B3k1\n",
    "    pai = att.sum(dim=3, keepdim=True) # B1K11\n",
    "    att = att / torch.clamp(pai, min=1e-3)\n",
    "    ts = torch.sum(\n",
    "        att * x[:, :, None, :, None], dim=3) # B3K1\n",
    "    return ts\n",
    "\n",
    "def equillibrium_loss(att):\n",
    "    pai = att.sum(dim=3, keepdim=True) # B1K11\n",
    "    loss_att_amount = torch.var(pai.reshape(pai.shape[0], -1), dim=1).mean()\n",
    "    return loss_att_amount\n",
    "\n",
    "\n",
    "def spatial_variance(x, att, norm_type=\"l2\"):\n",
    "    pai = att.sum(dim=3, keepdim=True) # B1K11\n",
    "    att = att / torch.clamp(pai, min=1e-3)\n",
    "    ts = torch.sum(\n",
    "        att * x[:, :, None, :, None], dim=3) # B3K1\n",
    "\n",
    "    x_centered = x[:, :, None] - ts # B3KN\n",
    "    x_centered = x_centered.permute(0, 2, 3, 1) # BKN3\n",
    "    att = att.squeeze(1) # BKN1\n",
    "    cov = torch.matmul(\n",
    "        x_centered.transpose(3, 2), att * x_centered) # BK33\n",
    "    \n",
    "    # l2 norm\n",
    "    vol = torch.diagonal(cov, dim1=-2, dim2=-1).sum(2) # BK\n",
    "    if norm_type == \"l2\":\n",
    "        vol = vol.norm(dim=1).mean()\n",
    "    elif norm_type == \"l1\":\n",
    "        vol = vol.sum(dim=1).mean()\n",
    "    else:\n",
    "        # vol, _ = torch.diagonal(cov, dim1=-2, dim2=-1).sum(2).max(dim=1)\n",
    "        raise NotImplementedError\n",
    "    return vol\n",
    "\n",
    "class RDB_Conv(nn.Module):\n",
    "    def __init__(self, inChannels, growRate, kSize=3):\n",
    "        super(RDB_Conv, self).__init__()\n",
    "        Cin = inChannels\n",
    "        G  = growRate\n",
    "        self.conv = nn.Sequential(*[\n",
    "            nn.Conv2d(Cin, G, kSize, padding=(kSize-1)//2, stride=1),\n",
    "            nn.ReLU(),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return torch.cat((x, out), 1)\n",
    "\n",
    "class RDB(nn.Module):\n",
    "    def __init__(self, growRate0, growRate, nConvLayers, kSize=3):\n",
    "        super(RDB, self).__init__()\n",
    "        G0 = growRate0\n",
    "        G  = growRate\n",
    "        C  = nConvLayers\n",
    "\n",
    "        convs = []\n",
    "        for c in range(C):\n",
    "            convs.append(RDB_Conv(G0 + c*G, G))\n",
    "        self.convs = nn.Sequential(*convs)\n",
    "\n",
    "        # Local Feature Fusion\n",
    "        self.LFF = nn.Conv2d(G0 + C*G, G0, 1, padding=0, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.LFF(self.convs(x)) + x\n",
    "\n",
    "class RDN(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(RDN, self).__init__()\n",
    "        self.args = args\n",
    "        r = args.scale[0]\n",
    "        G0 = args.G0\n",
    "        kSize = args.RDNkSize\n",
    "\n",
    "        # number of RDB blocks, conv layers, out channels\n",
    "        self.D, C, G = args.RDNconfig\n",
    "        \"\"\"\n",
    "        {\n",
    "            'A': (20, 6, 32),\n",
    "            'B': (16, 8, 64),\n",
    "        }[args.RDNconfig]\n",
    "        \"\"\"\n",
    "\n",
    "        # Shallow feature extraction net\n",
    "        self.SFENet1 = nn.Conv2d(args.n_colors, G0, kSize, padding=(kSize-1)//2, stride=1)\n",
    "        self.SFENet2 = nn.Conv2d(G0, G0, kSize, padding=(kSize-1)//2, stride=1)\n",
    "\n",
    "        # Redidual dense blocks and dense feature fusion\n",
    "        self.RDBs = nn.ModuleList()\n",
    "        for i in range(self.D):\n",
    "            self.RDBs.append(\n",
    "                RDB(growRate0 = G0, growRate = G, nConvLayers = C)\n",
    "            )\n",
    "\n",
    "        # Global Feature Fusion\n",
    "        self.GFF = nn.Sequential(*[\n",
    "            nn.Conv2d(self.D * G0, G0, 1, padding=0, stride=1),\n",
    "            nn.Conv2d(G0, G0, kSize, padding=(kSize-1)//2, stride=1)\n",
    "        ])\n",
    "\n",
    "        if args.no_upsampling:\n",
    "            self.out_dim = G0\n",
    "        else:\n",
    "            self.out_dim = args.n_colors\n",
    "            # Up-sampling net\n",
    "            if r == 2 or r == 3:\n",
    "                self.UPNet = nn.Sequential(*[\n",
    "                    nn.Conv2d(G0, G * r * r, kSize, padding=(kSize-1)//2, stride=1),\n",
    "                    nn.PixelShuffle(r),\n",
    "                    nn.Conv2d(G, args.n_colors, kSize, padding=(kSize-1)//2, stride=1)\n",
    "                ])\n",
    "            elif r == 4:\n",
    "                self.UPNet = nn.Sequential(*[\n",
    "                    nn.Conv2d(G0, G * 4, kSize, padding=(kSize-1)//2, stride=1),\n",
    "                    nn.PixelShuffle(2),\n",
    "                    nn.Conv2d(G, G * 4, kSize, padding=(kSize-1)//2, stride=1),\n",
    "                    nn.PixelShuffle(2),\n",
    "                    nn.Conv2d(G, args.n_colors, kSize, padding=(kSize-1)//2, stride=1)\n",
    "                ])\n",
    "            else:\n",
    "                raise ValueError(\"scale must be 2 or 3 or 4.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        f__1 = self.SFENet1(x)\n",
    "        x  = self.SFENet2(f__1)\n",
    "\n",
    "        RDBs_out = []\n",
    "        for i in range(self.D):\n",
    "            x = self.RDBs[i](x)\n",
    "            RDBs_out.append(x)\n",
    "\n",
    "        x = self.GFF(torch.cat(RDBs_out,1))\n",
    "        x += f__1\n",
    "\n",
    "        if self.args.no_upsampling:\n",
    "            return x\n",
    "        else:\n",
    "            return self.UPNet(x)\n",
    "\n",
    "class GraphConvolution(nn.Module):\n",
    "\n",
    "    def __init__(self, input_feature_num, output_feature_num, add_bias=True, dtype=torch.float,\n",
    "                 batch_normal=True):\n",
    "        super().__init__()\n",
    "        # shapes\n",
    "\n",
    "        self.input_feature_num = input_feature_num\n",
    "        self.output_feature_num = output_feature_num\n",
    "        self.add_bias = add_bias\n",
    "        self.batch_normal = batch_normal\n",
    "\n",
    "        # params\n",
    "        latent_dim = 128\n",
    "        self.weight = FCBlock(128,2,input_feature_num, latent_dim)\n",
    "        self.bias = nn.Parameter(torch.randn(latent_dim,dtype=dtype))\n",
    "        self.transform = FCBlock(128,2,latent_dim, self.output_feature_num)\n",
    "        \n",
    "        self.sparse = True\n",
    "        #self.batch_norm = nn.BatchNorm1d(num_features = input_feature_num)\n",
    "            \n",
    "    def set_trainable(self, train=True):\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = train\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        \"\"\"\n",
    "        @param inp : adjacent: (batch, graph_num, graph_num) cat node_feature: (batch, graph_num, in_feature_num) -> (batch, graph_num, graph_num + in_feature_num)\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        B, N, D = x.shape\n",
    "        node_feature = x\n",
    "\n",
    "        x = self.weight(node_feature)\n",
    "        #x = torch.nn.functional.normalize(x,p = 1.0, dim = -1, eps = 1e-5)\n",
    "\n",
    "        if self.sparse or isinstance(adj, torch.SparseTensor):\n",
    "            x = torch.spmm(adj,x[0]).unsqueeze(0)\n",
    "        else:\n",
    "            x = torch.matmul(adj,x[0])\n",
    "        #if self.add_bias:\n",
    "        x = x + self.bias.unsqueeze(0).unsqueeze(0).repeat(B,N,1)\n",
    "\n",
    "        x = self.transform(x)\n",
    "\n",
    "        #x = torch.nn.functional.normalize(x,p = 1.0, dim = -1, eps = 1e-5)\n",
    "\n",
    "        return x\n",
    "\n",
    "class GNNSoftPooling(nn.Module):\n",
    "    def __init__(self, input_feat_dim, output_node_num = 10):\n",
    "        super().__init__()\n",
    "        self.assignment_net = GraphConvolution(input_feat_dim, output_node_num)\n",
    "        self.feature_net =   GraphConvolution(input_feat_dim, input_feat_dim) \n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        B,N,D = x.shape\n",
    "        # B,N,N = adj.shape\n",
    "        if isinstance(adj, list):\n",
    "            output_node_features = []\n",
    "            output_new_adj = []\n",
    "            output_s_matrix = []\n",
    "            scale = 50\n",
    "            for i in range(len(adj)):\n",
    "                s_matrix = self.assignment_net(x[i:i+1], adj[i]) #[B,N,M]\n",
    "                \n",
    "                s_matrix = torch.softmax(s_matrix * scale , dim = 2)#.clamp(0.0+eps,1.0-eps)\n",
    "            \n",
    "                node_features = self.feature_net(x[i:i+1],adj[i]) #[B,N,D]\n",
    "                node_features = torch.einsum(\"bnm,bnd->bmd\",s_matrix,node_features) #[B,M,D]\n",
    "                # [Calculate New Cluster Adjacency]\n",
    "\n",
    "                adj[i] = adj[i]\n",
    "                #print(\"smt,adj\",s_matrix.max(),s_matrix.min(), adj[i].max(), adj[i].min())\n",
    "                #print(adj[i].shape, s_matrix.shape)\n",
    "                new_adj = torch.spmm(\n",
    "                    torch.spmm(\n",
    "                        s_matrix[0].permute(1,0),adj[i]\n",
    "                        ),s_matrix[0])\n",
    "                new_adj = new_adj / new_adj.max()\n",
    "                #print(\"new_adj\",new_adj[i].max(), new_adj[i].min())\n",
    "\n",
    "                output_node_features.append(node_features)\n",
    "                output_new_adj.append(new_adj)\n",
    "                output_s_matrix.append(s_matrix)\n",
    "\n",
    "            output_node_features = torch.cat(output_node_features, dim = 0)\n",
    "            output_s_matrix = torch.cat(output_s_matrix, dim = 0)\n",
    "        return output_node_features,output_new_adj,output_s_matrix\n",
    "\n",
    "def get_fourier_feature(grid, term = 7):\n",
    "    output_feature = []\n",
    "    for k in range(term):\n",
    "        output_feature.append(torch.sin(grid * (k + 1)))\n",
    "        output_feature.append(torch.cos(grid * (k + 1)))\n",
    "    output_feature = torch.cat(output_feature, dim = -1)\n",
    "    return output_feature\n",
    "\n",
    "class ObjectRender(nn.Module):\n",
    "    def __init__(self,config, conv_feature_dim):\n",
    "        super().__init__()\n",
    "        channel_dim = config.channel\n",
    "        spatial_dim = config.spatial_dim\n",
    "        fourier_dim = config.fourier_dim\n",
    "\n",
    "        self.conv_feature_dim = conv_feature_dim\n",
    "        self.render_block  = FCBlock(128,2,conv_feature_dim + spatial_dim + spatial_dim + 2*spatial_dim*fourier_dim,channel_dim)\n",
    "\n",
    "    def forward(self, latent, grid):\n",
    "        B,N,D = latent.shape\n",
    "        if len(grid.shape) == 4:\n",
    "            # grid: [B,W,H,2]\n",
    "            B, W, H, _ = grid.shape\n",
    "            expand_latent = latent.unsqueeze(2).unsqueeze(2)\n",
    "            expand_latent = expand_latent.repeat(1,1,W,H,1)\n",
    "            grid = grid.unsqueeze(1)\n",
    "            grid = grid.repeat(1,N,1,1,1)\n",
    "        if len(grid.shape) == 3:\n",
    "            # grid: [B,WH,2]\n",
    "            B, WH, _ = grid.shape\n",
    "            grid = grid.unsqueeze(1).repeat(1,N,1,1)\n",
    "            expand_latent = latent.unsqueeze(2).repeat(1,1,WH,1)\n",
    "        cat_feature = torch.cat([grid, expand_latent], dim = -1)\n",
    "        return self.render_block(cat_feature)\n",
    "\n",
    "\n",
    "class ValkyrNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        device = config.device\n",
    "        # construct the grid domain connection\n",
    "        self.imsize = config.imsize\n",
    "        self.perception_size = config.perception_size\n",
    "        # build the connection graph for the grid domain\n",
    "        self.spatial_coords = grid(self.imsize,self.imsize,device=device)\n",
    "        self.spatial_fourier_features = get_fourier_feature(self.spatial_coords, term = config.fourier_dim).to(device)\n",
    "        self.spatial_edges =  build_perception(self.imsize,self.perception_size,device = device).to_dense().to(device)\n",
    "        # [Grid Convs]\n",
    "        conv_feature_dim = config.conv_feature_dim\n",
    "        self.grid_convs = RDN(SimpleNamespace(G0=conv_feature_dim  ,RDNkSize=3,n_colors=3,RDNconfig=(4,3,16),scale=[2],no_upsampling=True))\n",
    "        \n",
    "        # [Diff Pool Construction]\n",
    "        hierarchy_nodes = config.hierarchy_construct \n",
    "        self.diff_pool = nn.ModuleList([\n",
    "            GNNSoftPooling(input_feat_dim = conv_feature_dim+2,output_node_num = node_num ) for node_num in hierarchy_nodes\n",
    "        ])\n",
    "        \n",
    "\n",
    "        # [Render Fields]\n",
    "        self.render_fields = nn.ModuleList([ObjectRender(config, conv_feature_dim) for _ in hierarchy_nodes])\n",
    "\n",
    "        self.conv2object_feature = nn.Linear(conv_feature_dim + 2, config.object_dim)\n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    def forward(self, x, verbose = 0):\n",
    "        outputs = {}\n",
    "        B,W,H,C = x.shape # input shape\n",
    "        device = self.device\n",
    "\n",
    "        # [Grid Convolution] produce initial feature in the grid domain \n",
    "        grid_conv_feature = self.grid_convs(x.permute(0,3,1,2)).to(device).permute(0,2,3,1)\n",
    "\n",
    "        _,_,_,D = grid_conv_feature.shape\n",
    "        coords_added_conv_feature = torch.cat(\n",
    "            [grid_conv_feature, self.spatial_coords.unsqueeze(0).repeat(B,1,1,1).to(device)], dim = 3\n",
    "        )\n",
    "        if verbose:print(\"coords_added_conv_feature:{}x{}x{}x{}\".format(*list(coords_added_conv_feature.shape) ))\n",
    "\n",
    "        coords_added_conv_feature = coords_added_conv_feature.reshape(B,W*H,(D+2))\n",
    "        coords_added_conv_feature = F.normalize(coords_added_conv_feature, dim = 2, p=1.0)\n",
    "       \n",
    "        # [DiffPool] each layer performs differentiable [Pn invariant] pooling \n",
    "\n",
    "        convs_features = []\n",
    "        cluster_assignments = []\n",
    "        curr_x = coords_added_conv_feature # base layer feature\n",
    "  \n",
    "        curr_edges = [self.spatial_edges for _ in range(B)] # base layer edges\n",
    "        convs_features.append(curr_x)\n",
    "        entropy_regular = 0.0 # initialize the entropy loss\n",
    "        loc_loss = 0.0        # localization loss\n",
    "        equi_loss = 0.0       # equillibrium loss\n",
    "        scene_tree = {\n",
    "            \"x\":[curr_x],\n",
    "            \"object_features\":[self.conv2object_feature(curr_x)],\n",
    "            \"object_scores\":[torch.ones(B,curr_x.shape[1]).to(self.device)],\n",
    "            \"connections\":[],\n",
    "            \"edges\":[self.spatial_edges]}\n",
    "        outputs[\"masks\"] = []\n",
    "\n",
    "        layer_reconstructions = []\n",
    "        layer_masks = [torch.ones(B,curr_x.shape[1]).to(self.device)]  # maintain a mask\n",
    "        for i,graph_pool in enumerate(self.diff_pool):\n",
    "            curr_x, curr_edges, assignment_matrix = graph_pool(curr_x, curr_edges)\n",
    "            B,N,M = assignment_matrix.shape\n",
    "            assignment_matrix = scene_tree[\"object_scores\"][-1].unsqueeze(2).repeat(1,1,M) * assignment_matrix\n",
    "            #assignment_matrix = F.normalize(assignment_matrix, dim = 2)\n",
    "\n",
    "            # previous level mask calculation\n",
    "            prev_mask = layer_masks[-1]\n",
    "            #print(prev_mask.shape, assignment_matrix.shape)\n",
    "            if len(prev_mask.shape) == 2:\n",
    "                layer_mask = assignment_matrix #[BxNxWxHx1]\n",
    "            else:layer_mask = torch.bmm(prev_mask,assignment_matrix)\n",
    "\n",
    "\n",
    "            layer_masks.append(layer_mask)\n",
    "            #print(layer_mask.shape)\n",
    "            exist_prob = torch.max(assignment_matrix,dim = 1).values\n",
    "            #exist_prob = torch.ones(B, assignment_matrix.shape[-1]).to(device)\n",
    "\n",
    "            # [Equivariance Loss]\n",
    "            equis =assignment_matrix.unsqueeze(1).unsqueeze(-1)\n",
    "            equi_loss += equillibrium_loss(equis)\n",
    "            \n",
    "            cluster_assignments.append(assignment_matrix)\n",
    "            convs_features.append(curr_x)\n",
    "\n",
    "            # [Scene Reconstruction]\n",
    "            syn_grid = torch.cat([self.spatial_coords.to(device)\\\n",
    "                                  ,self.spatial_fourier_features.to(device)], dim = -1).unsqueeze(0).repeat(B,1,1,1)\n",
    "\n",
    "            layer_recons = self.render_fields[i](\n",
    "                curr_x,\n",
    "                syn_grid\n",
    "                )\n",
    "\n",
    "            if verbose: print(\"reconstruction with shape: \", layer_recons.shape)\n",
    "            layer_reconstructions.append(layer_recons)\n",
    "            \n",
    "            if verbose:print(assignment_matrix.max(),assignment_matrix.min(), curr_edges[0].shape, curr_edges[0].max(), curr_edges[0].min())\n",
    "            \n",
    "            # [Regular Entropy Term]\n",
    "            \n",
    "            attention_mask = layer_mask\n",
    "            outputs[\"masks\"].append(attention_mask)\n",
    "            \n",
    "            points = self.spatial_coords.unsqueeze(0).repeat(B,1,1,1).reshape(B,W*H,2)\n",
    "            #print(attention_mask.shape, points.shape)\n",
    "            #pose_locals = evaluate_pose(points , attention_mask)\n",
    "            loc_loss += spatial_variance(points, attention_mask.permute(0,2,1), norm_type=\"l2\")\n",
    "            #equi_loss += equillibrium_loss(attention_mask)\n",
    "\n",
    "            entropy_regular += assignment_entropy(assignment_matrix)\n",
    "\n",
    "            # load results to the scene tree\n",
    "            scene_tree[\"x\"].append(curr_x)\n",
    "            scene_tree[\"object_features\"].append(self.conv2object_feature(curr_x))\n",
    "            scene_tree[\"object_scores\"].append(exist_prob)\n",
    "            scene_tree[\"connections\"].append(assignment_matrix)\n",
    "            scene_tree[\"edges\"].append(curr_edges)\n",
    "\n",
    "        # [Calculate Reconstruction at Each Layer]\n",
    "        outputs[\"reconstructions\"] = []\n",
    "\n",
    "        reconstruction_loss = 0.0\n",
    "\n",
    "        for i,recons in enumerate(layer_reconstructions):\n",
    "\n",
    "            B,N,W,H,C = recons.shape\n",
    "\n",
    "            exist_prob = scene_tree[\"object_scores\"][i+1]\\\n",
    "                .unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).repeat(1,1,W,H,C) \n",
    "\n",
    "            mask = layer_masks[i+1].permute(0,2,1).reshape(B,N,W,H,1)\n",
    "\n",
    "            recons = recons * mask * exist_prob\n",
    "            \n",
    "            #layer_recon_loss = torch.nn.functional.mse_loss(recons, x.unsqueeze(1).repeat(1,N,1,1,1))\n",
    "            layer_recon_loss = torch.nn.functional.mse_loss(recons.sum(dim = 1), x)\n",
    "            reconstruction_loss += layer_recon_loss\n",
    "            outputs[\"reconstructions\"].append(recons)\n",
    "\n",
    "\n",
    "        # [Output the Scene Tree]\n",
    "        outputs[\"scene_tree\"] = scene_tree\n",
    "\n",
    "        # [Add all the loss terms]\n",
    "        outputs[\"losses\"] = {\"entropy\":entropy_regular,\"reconstruction\":reconstruction_loss,\"equi\":equi_loss,\"localization\":loc_loss}\n",
    "        return outputs\n",
    "\n",
    "def evaluate_pose(x, att):\n",
    "    # x: BN3, att: BKN\n",
    "    # ts: B3k1\n",
    "    att = att.unsqueeze(1).unsqueeze(-1)\n",
    "    x = x.permute(0,2,1)\n",
    "    pai = att.sum(dim=3, keepdim=True) # B1K11\n",
    "    att = att / torch.clamp(pai, min=1e-3)\n",
    "    ts = torch.sum(\n",
    "        att * x[:, :, None, :, None], dim=3) # B3K1\n",
    "    return ts.permute(0,2,1,3).squeeze(-1)\n",
    "\n",
    "def spatial_variance(x, att, norm_type=\"l2\"):\n",
    "    # att: BKN x: BN3\n",
    "    x = x.permute(0,2,1)\n",
    "    att = att.unsqueeze(1).unsqueeze(-1)\n",
    "    pai = att.sum(dim=3, keepdim=True) # B1K11\n",
    "    att = att / torch.clamp(pai, min=1e-3)\n",
    "    ts = torch.sum(\n",
    "        att * x[:, :, None, :, None], dim=3) # B3K1\n",
    "\n",
    "    x_centered = x[:, :, None] - ts # B3KN\n",
    "    x_centered = x_centered.permute(0, 2, 3, 1) # BKN3\n",
    "    att = att.squeeze(1) # BKN1\n",
    "    cov = torch.matmul(\n",
    "        x_centered.transpose(3, 2), att * x_centered) # BK33\n",
    "    \n",
    "    # l2 norm\n",
    "    vol = torch.diagonal(cov, dim1=-2, dim2=-1).sum(2) # BK\n",
    "    if norm_type == \"l2\":\n",
    "        vol = vol.norm(dim=1).mean()\n",
    "    elif norm_type == \"l1\":\n",
    "        vol = vol.sum(dim=1).mean()\n",
    "    else:\n",
    "        # vol, _ = torch.diagonal(cov, dim1=-2, dim2=-1).sum(2).max(dim=1)\n",
    "        raise NotImplementedError\n",
    "    return vol\n",
    "\n",
    "def assignment_entropy(s_matrix):\n",
    "    # s_matrix: B,N,M\n",
    "    EPS = 1e-6\n",
    "    output_entropy = 0\n",
    "    for b in range(s_matrix.shape[0]):\n",
    "        for i in range(s_matrix.shape[1]):\n",
    "            input_tensor = s_matrix[b][i:i+1,:].clamp(EPS, 1-EPS)\n",
    "\n",
    "            lsm = nn.LogSoftmax(dim = -1)\n",
    "            log_probs = lsm(input_tensor)\n",
    "            probs = torch.exp(log_probs)\n",
    "            p_log_p = log_probs * probs\n",
    "            entropy = -p_log_p.mean()\n",
    "            #print(entropy)\n",
    "            output_entropy += entropy\n",
    "    output_entropy *= 0\n",
    "    return output_entropy\n",
    "    \n",
    "\n",
    "def equillibrium_loss(att):\n",
    "    pai = att.sum(dim=3, keepdim=True) # B1K11\n",
    "    loss_att_amount = torch.var(pai.reshape(pai.shape[0], -1), dim=1).mean()\n",
    "    return loss_att_amount\n",
    "\n",
    "def build_perception(size,length,device):\n",
    "    edges = [[],[]]\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            # go for all the points on the grid\n",
    "            coord = [i,j];loc = i * size + j\n",
    "\n",
    "            for dx in range(-length,length+1):\n",
    "                for dy in range(-length,length+1):\n",
    "                    if i+dx < size and i+dx>=0 and j+dy<size and j+dy>=0:\n",
    "                        if (i+dx) * size + (j + dy) != loc:\n",
    "                            edges[0].append(loc)\n",
    "                            edges[1].append( (i+dx) * size + (j + dy))\n",
    "                            edges[0].append( (i+dx) * size + (j + dy))\n",
    "                            edges[1].append(loc)\n",
    "    outputs = torch.sparse_coo_tensor(edges, torch.ones(len(edges[0])), size = (size**2, size**2))\n",
    "    return outputs.to(device)\n",
    "\n",
    "def grid(width, height, device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    x = torch.linspace(0,1,width)\n",
    "    y = torch.linspace(0,1,height)\n",
    "    grid_x, grid_y = torch.meshgrid(x, y, indexing='ij')\n",
    "    return torch.cat([grid_x.unsqueeze(0),grid_y.unsqueeze(0)], dim = 0).permute(1,2,0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.perception_size = 3\n",
    "config.hierarchy_construct = [5,3,2]\n",
    "config.conv_feature_dim = 128\n",
    "model.scene_perception = ValkyrNet(config)\n",
    "\n",
    "perception_outputs = model.scene_perception(sample[\"image\"])\n",
    "scene_tree = perception_outputs[\"scene_tree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "optimizer.zero_grad()\n",
    "working_loss = 0\n",
    "for key in perception_outputs[\"losses\"]: working_loss += perception_outputs[\"losses\"][key]\n",
    "working_loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_scene_tree(perception_outputs):\n",
    "    all_kwargs = []\n",
    "    scene_tree = perception_outputs[\"scene_tree\"]\n",
    "    scores = scene_tree[\"object_scores\"]\n",
    "    features = scene_tree[\"object_features\"]\n",
    "    connections = scene_tree[\"connections\"]\n",
    "\n",
    "    B = features[0].shape[0]\n",
    "    for b in range(B):\n",
    "        kw_scores, kw_features, kw_connections = [score[b] for score in scores], [feature[b] for feature in features], \\\n",
    "        [connection[b] for connection in connections]\n",
    "        kwargs = {\"features\":kw_features, \"end\":kw_scores, \"connections\":kw_connections}\n",
    "        all_kwargs.append(kwargs)\n",
    "    return all_kwargs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_tree = perception_outputs[\"scene_tree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = 1\n",
    "vis_scores = [score[b].detach() for score in scene_tree[\"object_scores\"][1:]]\n",
    "vis_connections = [connect[b] for connect in scene_tree[\"connections\"][1:]]\n",
    "\n",
    "\n",
    "visualize_tree(vis_scores, vis_connections, scale = 1.618)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16384, 5]) tensor(1., grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], grad_fn=<SumBackward1>)\n",
      "torch.Size([2, 16384, 3]) tensor(1., grad_fn=<MaxBackward1>) tensor(5.4651e-44, grad_fn=<MinBackward1>)\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], grad_fn=<SumBackward1>)\n",
      "torch.Size([2, 16384, 2]) tensor(1., grad_fn=<MaxBackward1>) tensor(3.6743e-36, grad_fn=<MinBackward1>)\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for mask in perception_outputs[\"masks\"]:\n",
    "    print(mask.shape,mask.max(), mask.min())\n",
    "    print(torch.sum(mask, dim = 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/c2bzzvd17y35z8x_20mfhn700000gn/T/ipykernel_33112/63699579.py:47: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.\n",
      "  plt.subplot(1,batch_size,i + 1,frameon=False)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [Visualize Predicate Segmentation]\n",
    "batch_kwargs = build_scene_tree(perception_outputs)\n",
    "#model.executor.effective_level = 3\n",
    "programs = [\"exist(scene())\",\"exist(filter(scene(),house))\"]\n",
    "for b in range(B):\n",
    "    kwargs = batch_kwargs[b]\n",
    "\n",
    "    q = programs[b]\n",
    "    q = model.executor.parse(q)\n",
    "    o = model.executor(q, **kwargs)\n",
    "    # [Visualize the Output Mask Scene Tree]\n",
    "    answer_distribution_binary(o[\"end\"].sigmoid().cpu().detach())\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "programs = [\"scene()\",\"filter(scene(),house)\"]\n",
    "for b in range(B):\n",
    "    kwargs = batch_kwargs[b]\n",
    "    q = programs[b]\n",
    "    q = model.executor.parse(q)\n",
    "    o = model.executor(q, **kwargs)\n",
    "\n",
    "    # [Visualize the Output Mask Scene Tree]\n",
    "    vis_connections = [connect[b] for connect in scene_tree[\"connections\"][1:]]\n",
    "    vis_scores = [o[\"end\"][i].sigmoid().cpu().detach() for i in range(4)][1:]\n",
    "    \n",
    "    visualize_tree(vis_scores, vis_connections, scale = 1.618)\n",
    "    plt.show()\n",
    "\n",
    "#masks = calculate_masks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000e+00 3.674283e-36]\n",
      "[1.0000000e+00 5.7453237e-44 2.1684095e-16]\n",
      "[9.8090893e-45 2.1278682e-20 1.0000000e+00 1.0577211e-25 2.1684095e-16]\n",
      "Max: 1.0 Min: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAAsTAAALEwEAmpwYAAACy0lEQVR4nO3YMQoDMQwAwdOR/39Z+YBJF7zFTCk3ahaBZ3cfoOe9vQBwJk6IEidEiROixAlRn1+PM+MrF/5sd+c0dzkhSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghanb39g7AgcsJUeKEKHFClDghSpwQJU6I+gI34gvJPjrjHQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 1.0 Min: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAAsTAAALEwEAmpwYAAACy0lEQVR4nO3YMQoDMQwAwdOR/39Z+YBJF7zFTCk3ahaBZ3cfoOe9vQBwJk6IEidEiROixAlRn1+PM+MrF/5sd+c0dzkhSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghanb39g7AgcsJUeKEKHFClDghSpwQJU6I+gI34gvJPjrjHQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 1.0 Min: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAAsTAAALEwEAmpwYAAACy0lEQVR4nO3YMQoDMQwAwdOR/39Z+YBJF7zFTCk3ahaBZ3cfoOe9vQBwJk6IEidEiROixAlRn1+PM+MrF/5sd+c0dzkhSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghanb39g7AgcsJUeKEKHFClDghSpwQJU6I+gI34gvJPjrjHQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/c2bzzvd17y35z8x_20mfhn700000gn/T/ipykernel_33112/2137611598.py:27: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.\n",
      "  plt.subplot(1,N,i + 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x108a642b0>"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_masks(scores, connections):\n",
    "    all_masks = []\n",
    "    for i in range(len(connections)):\n",
    "        curr_mask = scores[i+1].unsqueeze(-1)\n",
    "        for connection in reversed(connections[:i+1]):\n",
    "            curr_mask = torch.bmm(connection, curr_mask) # [BxNxM],[BxM]\n",
    "        all_masks.append(curr_mask)\n",
    "    return all_masks\n",
    "\n",
    "vis_score = scene_tree[\"object_scores\"]\n",
    "#vis_score[-1][0][1] = 0.5\n",
    "print(vis_score[-1][0].cpu().detach().numpy())\n",
    "print(vis_score[-2][0].cpu().detach().numpy())\n",
    "print(vis_score[-3][0].cpu().detach().numpy())\n",
    "all_masks = calculate_masks(vis_score,scene_tree[\"connections\"])\n",
    "\n",
    "for mask in all_masks:\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(mask[0].reshape(128,128).detach(), cmap = \"bone\")\n",
    "    print(\"Max:\",float(mask[0].max()),\"Min:\",float(mask[0].min()))\n",
    "    plt.show()\n",
    "\n",
    "plt.axis(\"off\")\n",
    "mask = scene_tree[\"connections\"][0].reshape(2,128,128,5).detach()\n",
    "N = 5\n",
    "for i in range(N):\n",
    "    plt.subplot(1,N,i + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(mask[0,:,:,i])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(sample[\"image\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2298)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.randn(2, 100, 2)\n",
    "attn = (torch.randn(2,5,100 ) ** 2).clamp(0.,1.0)\n",
    "\n",
    "local_loss = spatial_variance(x, attn)\n",
    "print(local_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0385)\n",
      "torch.Size([1, 1, 3, 2, 1])\n",
      "tensor(0.0633)\n"
     ]
    }
   ],
   "source": [
    "def assignment_entropy(s_matrix):\n",
    "    # s_matrix: B,N,M\n",
    "    EPS = 1e-6\n",
    "    output_entropy = 0\n",
    "    for b in range(s_matrix.shape[0]):\n",
    "        for i in range(s_matrix.shape[1]):\n",
    "            input_tensor = s_matrix[b][i:i+1,:].clamp(EPS, 1-EPS)\n",
    "\n",
    "            lsm = nn.LogSoftmax(dim = -1)\n",
    "            log_probs = lsm(input_tensor)\n",
    "            probs = torch.exp(log_probs)\n",
    "            p_log_p = log_probs * probs\n",
    "            entropy = -p_log_p.mean()\n",
    "            #print(entropy)\n",
    "            output_entropy += entropy\n",
    "\n",
    "    return output_entropy\n",
    "    \n",
    "\n",
    "def equillibrium_loss(att):\n",
    "    pai = att.sum(dim=3, keepdim=True) # B1K11\n",
    "    loss_att_amount = torch.var(pai.reshape(pai.shape[0], -1), dim=1).mean()\n",
    "    return loss_att_amount\n",
    "\n",
    "s_matrix = torch.tensor([\n",
    "    [0.5,0.4],\n",
    "    [0.2,0.2],\n",
    "    [0.3,0.4],\n",
    "]).unsqueeze(0)\n",
    "\n",
    "entropy_loss = assignment_entropy(s_matrix)\n",
    "print(entropy_loss)\n",
    "\n",
    "\n",
    "equis =s_matrix.unsqueeze(1).unsqueeze(-1)\n",
    "print(equis.shape)\n",
    "equi_loss = equillibrium_loss(equis)\n",
    "print(equi_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.7311, 0.2689],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.2689, 0.7311]])\n"
     ]
    }
   ],
   "source": [
    "S = torch.tensor([\n",
    "    [1, 0],\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "]).float()\n",
    "\n",
    "A = torch.tensor([\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 0],\n",
    "    [1, 0, 0]\n",
    "]).float()\n",
    "\n",
    "new_adj = torch.matmul(S.permute(1,0), torch.matmul(A, S))\n",
    "print(new_adj)\n",
    "\n",
    "normalize = torch.softmax(S, dim = 1)\n",
    "print(normalize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirs torch.Size([64, 64, 3])\n",
      "rays_d torch.Size([64, 64, 3])\n",
      "rays_o torch.Size([64, 64, 3])\n"
     ]
    }
   ],
   "source": [
    "from utils.render import *\n",
    "\n",
    "\n",
    "H, W = (64, 64)\n",
    "K = ((1, 0, 2),\n",
    "     (0, 1, 2),\n",
    "     (0, 0, 1))\n",
    "\n",
    "c2w = torch.tensor([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 1, 0],\n",
    "])\n",
    "\n",
    "rays_o, rays_d = get_rays(H, W, K, c2w, 0, 0, 0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a47e46093c771f9510c4aabf3710bfb1355e5f870a13f8c22092f45d4d23626d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Melkor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
