{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/melkor/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 128, 128, 3])\n",
      "torch.Size([65536]) torch.Size([65536])\n",
      "torch.Size([2140]) torch.Size([2140])\n",
      "level:0 torch.Size([4, 128, 128, 3])\n",
      "level:1 torch.Size([4, 128, 128, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from models import *\n",
    "from config import *\n",
    "\n",
    "from datasets import *\n",
    "\n",
    "import math\n",
    "\n",
    "dataset = ToyData(\"train\")\n",
    "\n",
    "idx = [4, 7, 9, 11]\n",
    "ims = torch.cat([dataset[i][\"image\"].unsqueeze(0) for i in idx])\n",
    "\n",
    "print(ims.shape)\n",
    "\n",
    "percept = PSGNet(config.imsize,3)\n",
    "\n",
    "\n",
    "outputs = percept(ims)\n",
    "\n",
    "def normalize_outputs(outputs):\n",
    "    recons = outputs[\"recons\"]\n",
    "    B = recons[0].shape[0]\n",
    "    W = int(math.sqrt(recons[0].shape[1]))\n",
    "\n",
    "    clusters  = outputs[\"clusters\"]\n",
    "    features  = outputs[\"features\"]\n",
    "    centroids = outputs[\"centroids\"]\n",
    "    moments   = outputs[\"moments\"]\n",
    "\n",
    "    for item in clusters:print(item[0].shape, item[1].shape)\n",
    "\n",
    "    level_reconstructions = [item.reshape([B,W,W,3]) for item in recons]\n",
    "\n",
    "    return {\"recons\":level_reconstructions, \"clusters\": clusters, \"features\": features, \"centroids\": centroids, \"moments\": moments}\n",
    "\n",
    "outputs = normalize_outputs(outputs)\n",
    "recons = outputs[\"recons\"]\n",
    "\n",
    "for i,item in enumerate(recons):print(\"level:{}\".format(i),item.shape)\n",
    "\n",
    "\n",
    "\n",
    "class AbstractNet(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_heads =8\n",
    "        self.feature_decoder = nn.Transformer(nhead=16, num_encoder_layers=12,d_model = config.global_feature_dim,batch_first = True)\n",
    "        self.spatial_decoder = nn.Transformer(nhead=16, num_encoder_layers=12,d_model = config.global_feature_dim,batch_first = True)\n",
    "        self.source_heads = nn.Parameter(torch.randn([self.num_heads,config.global_feature_dim]))\n",
    "\n",
    "        self.coordinate_decoder = nn.Linear(config.global_feature_dim, 2)\n",
    "    \n",
    "    def forward(self, feature, spatial):\n",
    "        B, M, C = feature.shape\n",
    "        N = self.num_heads\n",
    "        # [Feature Propagation]\n",
    "        component_features = feature\n",
    "        component_spaitals = spatial\n",
    "\n",
    "        # [Decode Proposals]\n",
    "        global_feature = torch.randn()\n",
    "        source_heads = self.souce_heads\n",
    "        feature_proposals = self.feature_decoder(source_heads,global_feature)\n",
    "        spaital_proposals = self.spatial_decoder(source_heads,global_feature)\n",
    "\n",
    "        # [Component Matching]\n",
    "        # component_features : [B,M,C]\n",
    "        # feature_proposals  : [B,N,C]\n",
    "\n",
    "        match = torch.softmax(torch.einsum(\"bnc,bmc -> bnm\",component_features, proposal_features)/math.sqrt(C), dim = -1)\n",
    "        existence = torch.max(match, dim = 1).values  # [B, N, 1]\n",
    "\n",
    "        # [Construct Representation]\n",
    "        output_graph = 0\n",
    "\n",
    "        return output_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters\n",
      "torch.Size([65536]) torch.Size([65536])\n",
      "torch.Size([2140]) torch.Size([2140])\n",
      "features\n",
      "torch.Size([2140, 64])\n",
      "torch.Size([869, 64])\n",
      "centroids\n",
      "torch.Size([2140, 2])\n",
      "torch.Size([869, 2])\n",
      "moments\n",
      "torch.Size([2140, 2])\n",
      "torch.Size([869, 2])\n"
     ]
    }
   ],
   "source": [
    "print(\"clusters\")\n",
    "clusters = outputs[\"clusters\"]\n",
    "for item in clusters:\n",
    "    nodes = item[0]\n",
    "    batch = item[1]\n",
    "    print(nodes.shape, batch.shape)\n",
    "\n",
    "\n",
    "print(\"features\")\n",
    "features = outputs[\"features\"]\n",
    "for item in features:\n",
    "    print(item.shape)\n",
    "\n",
    "\n",
    "print(\"centroids\")\n",
    "features = outputs[\"centroids\"]\n",
    "for item in features:\n",
    "    print(item.shape)\n",
    "\n",
    "print(\"moments\")\n",
    "features = outputs[\"moments\"]\n",
    "for item in features:\n",
    "    print(item.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level: 0\n",
      "torch.Size([2140, 64]) torch.Size([2140, 2]) torch.Size([2140, 2])\n",
      "torch.Size([4, 547, 64]) torch.Size([4, 547, 2]) torch.Size([4, 547, 2])\n",
      "level: 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/melkor/Documents/GitHub/SceneGraphLearner/view.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melkor/Documents/GitHub/SceneGraphLearner/view.ipynb#ch0000002?line=19'>20</a>\u001b[0m         moment,   batch \u001b[39m=\u001b[39m to_dense_batch(moments[i],cast_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melkor/Documents/GitHub/SceneGraphLearner/view.ipynb#ch0000002?line=21'>22</a>\u001b[0m         \u001b[39mprint\u001b[39m(feature\u001b[39m.\u001b[39mshape, centroid\u001b[39m.\u001b[39mshape, moment\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/melkor/Documents/GitHub/SceneGraphLearner/view.ipynb#ch0000002?line=24'>25</a>\u001b[0m to_dense_features(outputs)\n",
      "\u001b[1;32m/Users/melkor/Documents/GitHub/SceneGraphLearner/view.ipynb Cell 3'\u001b[0m in \u001b[0;36mto_dense_features\u001b[0;34m(outputs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melkor/Documents/GitHub/SceneGraphLearner/view.ipynb#ch0000002?line=10'>11</a>\u001b[0m nodes \u001b[39m=\u001b[39m clusters[i][\u001b[39m0\u001b[39m];batch \u001b[39m=\u001b[39m clusters[i][\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melkor/Documents/GitHub/SceneGraphLearner/view.ipynb#ch0000002?line=12'>13</a>\u001b[0m \u001b[39m#cast_batch = to_dense_batch(nodes,batch)[0]\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/melkor/Documents/GitHub/SceneGraphLearner/view.ipynb#ch0000002?line=13'>14</a>\u001b[0m cast_batch \u001b[39m=\u001b[39m clusters[i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melkor/Documents/GitHub/SceneGraphLearner/view.ipynb#ch0000002?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(sparse_feature\u001b[39m.\u001b[39mshape,sparse_centroid\u001b[39m.\u001b[39mshape, sparse_moment\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/melkor/Documents/GitHub/SceneGraphLearner/view.ipynb#ch0000002?line=17'>18</a>\u001b[0m feature,  batch \u001b[39m=\u001b[39m to_dense_batch(features[i],cast_batch)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def to_dense_features(outputs):\n",
    "    clusters = outputs[\"clusters\"]\n",
    "    features = outputs[\"features\"]\n",
    "    centroids = outputs[\"centroids\"]\n",
    "    moments = outputs[\"moments\"]\n",
    "    for i in range(len(clusters)):\n",
    "        print(\"level:\",i)\n",
    "        sparse_feature = features[i]\n",
    "        sparse_centroid = centroids[i]\n",
    "        sparse_moment = moments[i]\n",
    "        nodes = clusters[i][0];batch = clusters[i][1]\n",
    "\n",
    "        #cast_batch = to_dense_batch(nodes,batch)[0]\n",
    "        cast_batch = clusters[i+1][1]\n",
    "\n",
    "        print(sparse_feature.shape,sparse_centroid.shape, sparse_moment.shape)\n",
    "\n",
    "        feature,  batch = to_dense_batch(features[i],cast_batch)\n",
    "        centroid, batch = to_dense_batch(centroids[i],cast_batch)\n",
    "        moment,   batch = to_dense_batch(moments[i],cast_batch)\n",
    "\n",
    "        print(feature.shape, centroid.shape, moment.shape)\n",
    "\n",
    "\n",
    "to_dense_features(outputs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a47e46093c771f9510c4aabf3710bfb1355e5f870a13f8c22092f45d4d23626d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Melkor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
