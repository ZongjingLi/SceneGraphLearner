{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/melkor/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 128, 128, 3])\n",
      "torch.Size([65536]) torch.Size([65536])\n",
      "torch.Size([2140]) torch.Size([2140])\n",
      "level:0 torch.Size([4, 128, 128, 3])\n",
      "level:1 torch.Size([4, 128, 128, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from models import *\n",
    "from config import *\n",
    "\n",
    "from datasets import *\n",
    "\n",
    "import math\n",
    "\n",
    "dataset = ToyData(\"train\")\n",
    "\n",
    "idx = [4, 7, 9, 11]\n",
    "ims = torch.cat([dataset[i][\"image\"].unsqueeze(0) for i in idx])\n",
    "\n",
    "print(ims.shape)\n",
    "\n",
    "percept = PSGNet(config.imsize,3)\n",
    "\n",
    "\n",
    "outputs = percept(ims)\n",
    "\n",
    "def normalize_outputs(outputs):\n",
    "    recons = outputs[\"recons\"]\n",
    "    B = recons[0].shape[0]\n",
    "    W = int(math.sqrt(recons[0].shape[1]))\n",
    "\n",
    "    clusters  = outputs[\"clusters\"]\n",
    "    features  = outputs[\"features\"]\n",
    "    centroids = outputs[\"centroids\"]\n",
    "    moments   = outputs[\"moments\"]\n",
    "\n",
    "    for item in clusters:print(item[0].shape, item[1].shape)\n",
    "\n",
    "    level_reconstructions = [item.reshape([B,W,W,3]) for item in recons]\n",
    "\n",
    "    return {\"recons\":level_reconstructions, \"clusters\": clusters, \"features\": features, \"centroids\": centroids, \"moments\": moments}\n",
    "\n",
    "outputs = normalize_outputs(outputs)\n",
    "recons = outputs[\"recons\"]\n",
    "\n",
    "for i,item in enumerate(recons):print(\"level:{}\".format(i),item.shape)\n",
    "\n",
    "\n",
    "\n",
    "class AbstractNet(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_heads =8\n",
    "        self.feature_decoder = nn.Transformer(nhead=16, num_encoder_layers=12,d_model = config.global_feature_dim,batch_first = True)\n",
    "        self.spatial_decoder = nn.Transformer(nhead=16, num_encoder_layers=12,d_model = config.global_feature_dim,batch_first = True)\n",
    "        self.source_heads = nn.Parameter(torch.randn([self.num_heads,config.global_feature_dim]))\n",
    "\n",
    "        self.coordinate_decoder = nn.Linear(config.global_feature_dim, 2)\n",
    "    \n",
    "    def forward(self, feature, spatial):\n",
    "        B, M, C = feature.shape\n",
    "        N = self.num_heads\n",
    "        # [Feature Propagation]\n",
    "        component_features = feature\n",
    "        component_spaitals = spatial\n",
    "\n",
    "        # [Decode Proposals]\n",
    "        global_feature = torch.randn()\n",
    "        source_heads = self.souce_heads\n",
    "        feature_proposals = self.feature_decoder(source_heads,global_feature)\n",
    "        spaital_proposals = self.spatial_decoder(source_heads,global_feature)\n",
    "\n",
    "        # [Component Matching]\n",
    "        # component_features : [B,M,C]\n",
    "        # feature_proposals  : [B,N,C]\n",
    "\n",
    "        match = torch.softmax(torch.einsum(\"bnc,bmc -> bnm\",component_features, proposal_features)/math.sqrt(C), dim = -1)\n",
    "        existence = torch.max(match, dim = 1).values  # [B, N, 1]\n",
    "\n",
    "        # [Construct Representation]\n",
    "        output_graph = 0\n",
    "\n",
    "        return output_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters\n",
      "torch.Size([65536]) torch.Size([65536])\n",
      "torch.Size([2140]) torch.Size([2140])\n",
      "features\n",
      "torch.Size([2140, 64])\n",
      "torch.Size([869, 64])\n",
      "centroids\n",
      "torch.Size([2140, 2])\n",
      "torch.Size([869, 2])\n",
      "moments\n",
      "torch.Size([2140, 2])\n",
      "torch.Size([869, 2])\n"
     ]
    }
   ],
   "source": [
    "print(\"clusters\")\n",
    "clusters = outputs[\"clusters\"]\n",
    "for item in clusters:\n",
    "    nodes = item[0]\n",
    "    batch = item[1]\n",
    "    print(nodes.shape, batch.shape)\n",
    "\n",
    "\n",
    "print(\"features\")\n",
    "features = outputs[\"features\"]\n",
    "for item in features:\n",
    "    print(item.shape)\n",
    "\n",
    "\n",
    "print(\"centroids\")\n",
    "features = outputs[\"centroids\"]\n",
    "for item in features:\n",
    "    print(item.shape)\n",
    "\n",
    "print(\"moments\")\n",
    "features = outputs[\"moments\"]\n",
    "for item in features:\n",
    "    print(item.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level: 0\n",
      "(tensor([[1868, 2139, 2139,  ...,  496,  496, 1595],\n",
      "        [1307, 1303, 1303,  ...,  763,  763, 1455],\n",
      "        [1063,  760,  760,  ...,  324,  324, 1810],\n",
      "        [ 547,  322,  322,  ..., 1686, 1686, 1884]]), tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]]))\n",
      "level: 1\n",
      "(tensor([[  0,   0,   0,  ...,   0, 867, 460],\n",
      "        [856, 116, 458,  ..., 210, 781, 206],\n",
      "        [655, 689, 593,  ...,   0, 454, 443],\n",
      "        [480, 452, 668,  ...,   0,   0,   0]]), tensor([[False, False, False,  ..., False,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ..., False,  True,  True],\n",
      "        [ True,  True,  True,  ..., False, False, False]]))\n"
     ]
    }
   ],
   "source": [
    "def to_dense_features(outputs):\n",
    "    clusters = outputs[\"clusters\"]\n",
    "    features = outputs[\"features\"]\n",
    "    centroids = outputs[\"centroids\"]\n",
    "    moments = outputs[\"moments\"]\n",
    "    for i in range(len(clusters)):\n",
    "        print(\"level:\",i)\n",
    "        nodes = clusters[i][0]\n",
    "        batch = clusters[i][1]\n",
    "        print(to_dense_batch(nodes,batch))\n",
    "\n",
    "to_dense_features(outputs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a47e46093c771f9510c4aabf3710bfb1355e5f870a13f8c22092f45d4d23626d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Melkor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
